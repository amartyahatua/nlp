{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_trans_gan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8TloR3jTve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "import numpy as np \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXMDL7arlNZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "    def lengthWordToIndex(self):\n",
        "        return len(self.word2index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGfrK69ZlRoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijn9LRjClUer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('%s_%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emcr_586lXay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTbPJ-JclaKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "09fa0ab0-09b1-49f7-8a5d-30fc1791ba96"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'gar', True)\n",
        "\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 169813 sentence pairs\n",
            "Trimmed to 9404 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "gar 4434\n",
            "eng 2872\n",
            "['sie ist schlechter laune .', 'she s in a bad mood .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTZGtAjleww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93-pgjqElzDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=10):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        \n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnuLZm1al8nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RAvdiFrmRzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9861ab14-77eb-4afa-d1ed-f8d61a5b075a"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "encoder1.load_state_dict(torch.load('encoder.dict'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkKfekl9mZr6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd92e910-ef4a-41fb-8a92-8ee82bc918d2"
      },
      "source": [
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "attn_decoder1.load_state_dict(torch.load('decoder.dict'))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX7qzeOAmnSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, block_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(block_dim, block_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(block_dim, block_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x) + x\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, n_layers, block_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            *[Block(block_dim) for _ in range(n_layers)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pVGmTBZn9OB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testGan(encoder, decoder, sentence, max_length=10):\n",
        "    with torch.no_grad():\n",
        "      \n",
        "        input_length = sentence.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "        encoder_outputs[0: input_length,:] = sentence\n",
        "        # for ei in range(input_length):\n",
        "        #     encoder_output, encoder_hidden = encoder(sentence[ei],\n",
        "        #                                              encoder_hidden)\n",
        "        #     encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "        # print(\"decoder_input\",decoder_input.shape)\n",
        "        # print(\"decoder_hidden\",decoder_hidden.shape)\n",
        "        # print(\"encoder_outputs\",encoder_outputs.shape)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbybWM_anoJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import randint\n",
        "\n",
        "def evaluateGAN(encoder, decoder, n=200):\n",
        "    latent_dim = 256\n",
        "    n_layers = 20\n",
        "    block_dim = 256\n",
        "\n",
        "    for i in range(n):\n",
        "        generator = Generator(n_layers, block_dim)\n",
        "        generator.eval()\n",
        "        generator.load_state_dict(torch.load('generator.th', map_location='cpu'))\n",
        "        input_tensor = [[85],[86],[109],[1362],[2],[6],[1]]\n",
        "        input_tensor = np.asarray(input_tensor)\n",
        "        noise = torch.from_numpy(np.random.randint(1, 4434, (10, latent_dim)))\n",
        "        #noise = torch.from_numpy(input_tensor).float()\n",
        "        #z = generator(noise)\n",
        "        #print(\"Z shape=\",z.shape)\n",
        "        #print(\"z=\", z)\n",
        "        pair = random.choice(pairs)\n",
        "        #print('>', pair[0])\n",
        "        #print('=', pair[1])\n",
        "        output_words, attentions = testGan(encoder, decoder, noise)\n",
        "        #output_words, attentions = testGan(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bqo9iSbn8V9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b1c14a6-b225-464f-bdc7-f1abc6e664e1"
      },
      "source": [
        "evaluateGAN(encoder1,attn_decoder1)\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "< old in her her her her in her her her\n",
            "\n",
            "< my early in early in early in early in early\n",
            "\n",
            "< to my to to to to to to to to\n",
            "\n",
            "< to my too my my students students students students students\n",
            "\n",
            "< to to to at . to at . to to\n",
            "\n",
            "< at to to to to to . in in in\n",
            "\n",
            "< to . . . . . . . . .\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< . at in at in at in at in at\n",
            "\n",
            "< to students to students at in students about in students\n",
            "\n",
            "< and my my my my my my my my my\n",
            "\n",
            "< . to . to . to . to . to\n",
            "\n",
            "< a to to to to to to to to to\n",
            "\n",
            "< in to students in to students students in to students\n",
            "\n",
            "< . . . . . . . . . .\n",
            "\n",
            "< in at at at at at at at at at\n",
            "\n",
            "< to to to to to to to to to to\n",
            "\n",
            "< to . to to to . in in in in\n",
            "\n",
            "< in at . at at at at at at at\n",
            "\n",
            "< in . . . . . . . . .\n",
            "\n",
            "< a in at good good good in at good good\n",
            "\n",
            "< my my my my my my my my my my\n",
            "\n",
            "< students in in in in in in in in in\n",
            "\n",
            "< to . my my my my my my my my\n",
            "\n",
            "< in my my my my my my my my my\n",
            "\n",
            "< at . my . my . my my my my\n",
            "\n",
            "< students my to to to good to to early my\n",
            "\n",
            "< my you . . . . . . . .\n",
            "\n",
            "< good at to at to at to at at at\n",
            "\n",
            "< students . you you you you you you you you\n",
            "\n",
            "< in . . . . . . . . .\n",
            "\n",
            "< in . . . . . . . . .\n",
            "\n",
            "< my to to to . to . to to to\n",
            "\n",
            "< to in my my to my my my to my\n",
            "\n",
            "< at students . the students in my my students your\n",
            "\n",
            "< to stupid stupid stupid stupid stupid stupid students in students\n",
            "\n",
            "< you in in . in in . in in in\n",
            "\n",
            "< to about here to about at to to about at\n",
            "\n",
            "< students my in in in in in in in in\n",
            "\n",
            "< to my . . . . . . . .\n",
            "\n",
            "< to in in in in in in in in in\n",
            "\n",
            "< in to to to to to to to to to\n",
            "\n",
            "< students students students students students students students students students students\n",
            "\n",
            "< to to . students stupid students stupid students stupid students\n",
            "\n",
            "< to to to in . . . . . .\n",
            "\n",
            "< with at . at . at . at to to\n",
            "\n",
            "< . . . . . . . . . .\n",
            "\n",
            "< to a to to to to to to to to\n",
            "\n",
            "< to to to to to to to to to to\n",
            "\n",
            "< at in students in students in students in students in\n",
            "\n",
            "< to good good good good good good good good good\n",
            "\n",
            "< in . . . . . . . . .\n",
            "\n",
            "< to to at in to . to in to .\n",
            "\n",
            "< to at at at at at at at at at\n",
            "\n",
            "< at good at in at in at in at in\n",
            "\n",
            "< my my my my my my to my my my\n",
            "\n",
            "< at to . . . . . . . .\n",
            "\n",
            "< to you students in students to . . . .\n",
            "\n",
            "< my to to to to to to to to to\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< to in in in in in in in in in\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< in stupid stupid stupid stupid stupid stupid stupid . stupid\n",
            "\n",
            "< my in in in in in in in in in\n",
            "\n",
            "< my to to to to to to to to to\n",
            "\n",
            "< my to in my my my my my my my\n",
            "\n",
            "< to my students good students good students good students good\n",
            "\n",
            "< students to in students in students in students in students\n",
            "\n",
            "< to in my my my my my my my my\n",
            "\n",
            "< at to . . . . . . . .\n",
            "\n",
            "< to to in my to in . . . .\n",
            "\n",
            "< . . . . . . . . . .\n",
            "\n",
            "< my my my my my my my my my my\n",
            "\n",
            "< in students students in students in students students students in\n",
            "\n",
            "< in to to to to to to to to to\n",
            "\n",
            "< to students at at at at at at at at\n",
            "\n",
            "< in at a in in in in in in in\n",
            "\n",
            "< in a at at to to to to to to\n",
            "\n",
            "< day in students in students in my my my students\n",
            "\n",
            "< . old in your . old to to in old\n",
            "\n",
            "< to at to in to to to to to to\n",
            "\n",
            "< . to . my my to . my to my\n",
            "\n",
            "< to at in . . . . . . .\n",
            "\n",
            "< in my my my my my my my my my\n",
            "\n",
            "< students in my my my my my my my my\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< students in my my my my my my my my\n",
            "\n",
            "< to students to students to in in in in in\n",
            "\n",
            "< my my . . . . . . . .\n",
            "\n",
            "< . my my my my my my my my my\n",
            "\n",
            "< at in in in in in in in in in\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< to to to to to to to to to to\n",
            "\n",
            "< to to . . . . . . . .\n",
            "\n",
            "< with to in at in at in at to to\n",
            "\n",
            "< a at . at . at . at . at\n",
            "\n",
            "< to to my my my my to my my my\n",
            "\n",
            "< in at now to in at a in at a\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< to to to to my to my to my to\n",
            "\n",
            "< my with in in with in in in in in\n",
            "\n",
            "< to to in at . at in at . at\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< in . . . . . . . . .\n",
            "\n",
            "< with to to . to to to at in in\n",
            "\n",
            "< students you in in in in in in in in\n",
            "\n",
            "< to in to to to at . with . at\n",
            "\n",
            "< to at to in to in to in to in\n",
            "\n",
            "< . stupid stupid stupid stupid stupid stupid stupid stupid stupid\n",
            "\n",
            "< to my my my my my my my my my\n",
            "\n",
            "< to to to to to to to to to to\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< at to to to to to to to to to\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< in your your your your your in my my my\n",
            "\n",
            "< a to in to in to in to to to\n",
            "\n",
            "< . . . . . . . . . .\n",
            "\n",
            "< at to here in in in in in in in\n",
            "\n",
            "< students in my my my my stupid in my to\n",
            "\n",
            "< . . . . . . . . . .\n",
            "\n",
            "< . . . . . . . . . .\n",
            "\n",
            "< in at in my to . at in to .\n",
            "\n",
            "< . . . . . . . . . .\n",
            "\n",
            "< to a a to a to a to a a\n",
            "\n",
            "< . to you to to to to my to .\n",
            "\n",
            "< to in in in in in in in in in\n",
            "\n",
            "< students to a . my to my to to to\n",
            "\n",
            "< to to to to to to to to to to\n",
            "\n",
            "< my . . . . . . . . .\n",
            "\n",
            "< stupid my a to a in a to a to\n",
            "\n",
            "< my my to to to students students stupid stupid students\n",
            "\n",
            "< to a students in my my my a students in\n",
            "\n",
            "< to to to to to to to in to to\n",
            "\n",
            "< to a a a in a a in a to\n",
            "\n",
            "< in your to to to to in in in in\n",
            "\n",
            "< my with in to to my to to to to\n",
            "\n",
            "< students my my my my my . a . a\n",
            "\n",
            "< to in in in in in in in in in\n",
            "\n",
            "< in at in at at in in in in in\n",
            "\n",
            "< at students students students students in in in in in\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< in . . . . . . . . .\n",
            "\n",
            "< my to to to to to to to to to\n",
            "\n",
            "< to in in in in in in in in in\n",
            "\n",
            "< to . . . . . . . . .\n",
            "\n",
            "< students in students in students in students in students in\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< . to students at my to to at to .\n",
            "\n",
            "< to to to to to at to to to to\n",
            "\n",
            "< . students to to to to to to to to\n",
            "\n",
            "< my with at at in to in to to to\n",
            "\n",
            "< to in in in in in in in in in\n",
            "\n",
            "< in . . . . . . . . .\n",
            "\n",
            "< with my to good to my to to to to\n",
            "\n",
            "< . to good to at in at in at in\n",
            "\n",
            "< stupid students . students . students . students . students\n",
            "\n",
            "< in you you you you you you you you you\n",
            "\n",
            "< to to at students students students students students students students\n",
            "\n",
            "< in to to to to at my . to at\n",
            "\n",
            "< . in in in in in in in in in\n",
            "\n",
            "< . in in in in in in in in in\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< to at at to to to to . in in\n",
            "\n",
            "< in my my my my my my my my my\n",
            "\n",
            "< crazy my my my my my my my my my\n",
            "\n",
            "< to my my my my my my my my my\n",
            "\n",
            "< in old at . . . . . . .\n",
            "\n",
            "< . students in students in students in students in students\n",
            "\n",
            "< with . to my to to . to to .\n",
            "\n",
            "< in my my my my my my my my my\n",
            "\n",
            "< at . at . at . at . at .\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< at to to to to to to to to to\n",
            "\n",
            "< in . . . . . . . . .\n",
            "\n",
            "< . in in in in in in in in in\n",
            "\n",
            "< my in in in in in in in in in\n",
            "\n",
            "< a in in in in in in in in in\n",
            "\n",
            "< . in in in in in in in in in\n",
            "\n",
            "< my my my my my my my my my my\n",
            "\n",
            "< old in in in in in in in in in\n",
            "\n",
            "< night crazy a in in in in in in in\n",
            "\n",
            "< my to to to to to to to to to\n",
            "\n",
            "< my and my to to to to to to to\n",
            "\n",
            "< to at early early early early early early early early\n",
            "\n",
            "< students at at at at at at at at at\n",
            "\n",
            "< to my my my my my my my my my\n",
            "\n",
            "< in in in in in in in in in in\n",
            "\n",
            "< . students in students in students in students in students\n",
            "\n",
            "< to to to to to to to to to to\n",
            "\n",
            "< to at at at at at at at at at\n",
            "\n",
            "< my in in in in in in in in in\n",
            "\n",
            "< in to in to to to too to to to\n",
            "\n",
            "< stupid to to to to to to in to to\n",
            "\n",
            "< to in my my my my my my my my\n",
            "\n",
            "< to . to to to to to to to to\n",
            "\n",
            "< in a at a a a at a at at\n",
            "\n",
            "< . old in old . old to to to to\n",
            "\n",
            "< my to to in to my . to in to\n",
            "\n",
            "< my in with in with at at at at at\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}